verbose: True
log_wandb: True


data:

  import_data: True
  export_data: True

  dataset:
    path: ${hydra:runtime.cwd}/data/CED/SFLL
    volumes: [1889, 1906]
    patch_size: 16
    cut_image: True


  graph_configuration:
    attribute_type_of_nodes: ["nom", "cognom_1", "cognom_2"]
    entity_type_of_nodes: ["individual", "line"]
    attribute_edges: ["nom", "cognom_1", "cognom_2"]
    entity_edges : ["same_as", "family"]
    node_embedding_size: ${models.common_configuration.embedding_size}
    edge_embedding_size: ${models.common_configuration.embedding_size}

  collator:
    shuffle: True
    batch_size: 256
    partitions_ratio: [0.8, 0.1, 0.1]



models:


  finetune: False
  add_visual_encoder: True
  add_language: False
  name_checkpoint: "MMGC_Experiment_1_New_Edge_PE_Attention_language"


  visual_encoder:
    input_channels: 3
    hidden_channels: 32
    output_channels: 300
    number_of_hidden_convolutions: 3
    kernel_height: [5, 5, 5, 5, 5]
    kernel_width: [3, 3, 3, 3, 3]


setup:



  configuration:
    optimize_task: Loss
    batch_size: ${data.collator.batch_size}
    patch_size: 16
    epochs: 200
    embedding_size: ${models.common_configuration.embedding_size}
    dataset: BALL
    lr: 1e-4
    visual_encoder_convolutions: ${models.visual_encoder.number_of_hidden_convolutions}
    visual_encoder_hidden_channels: ${models.visual_encoder.hidden_channels}
    edge_visual_encoder_hidden_channels: ${models.edge_visual_encoder.hidden_channels}
    compute_loss_on: ["nom", "cognom_1", "cognom_2", "individual"]



  optimizer:
    _target_: torch.optim.Adam
    lr: ${setup.configuration.lr}

  
  wandb:
    project: "tfm"
    config: ${setup.configuration}
    notes: "Experiment 1"
    name: "Experiment 1 with positional embedding no Attention and language"
    group: "Attention Experiments Experiment 1"




